{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edcaddc5-d043-4913-b92d-b26560fe9a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "Shape of Complete Data Set\n",
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the creditcard.csv using pandas\n",
    "datainput = pd.read_csv(\"datasets/creditcard.csv\")\n",
    "# https://www.Rkaggle.com/mlg-ulb/creditcardfraud\n",
    "# Print the top 5 records\n",
    "print(datainput[0:5])\n",
    "# Print the complete shape of the dataset\n",
    "print(\"Shape of Complete Data Set\")\n",
    "print(datainput.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f8cfb2-4850-461f-9e55-2f2a49131f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017304750013189597\n",
      "False Detection Cases: 492\n",
      "True Detection Cases: 284315\n"
     ]
    }
   ],
   "source": [
    "cls = datainput.get(\"Class\")\n",
    "false = datainput[cls == 1]\n",
    "true = datainput[cls == 0]\n",
    "n = len(false) / float(len(true))\n",
    "print(n)\n",
    "print(\"False Detection Cases: {}\".format(len(datainput[cls == 1])))\n",
    "print(\"True Detection Cases: {}\".format(len(datainput[cls == 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c6cf8c2-7395-468c-984d-1aed0caf0ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Detection Cases\n",
      "----------------------\n",
      "count     492.000000\n",
      "mean      122.211321\n",
      "std       256.683288\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         9.250000\n",
      "75%       105.890000\n",
      "max      2125.870000\n",
      "Name: Amount, dtype: float64\n",
      "True Detection Cases\n",
      "----------------------\n",
      "count    284315.000000\n",
      "mean         88.291022\n",
      "std         250.105092\n",
      "min           0.000000\n",
      "25%           5.650000\n",
      "50%          22.000000\n",
      "75%          77.050000\n",
      "max       25691.160000\n",
      "Name: Amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# False Detection Cases\n",
    "print(\"False Detection Cases\")\n",
    "print(\"----------------------\")\n",
    "print(false.Amount.describe())\n",
    "# True Detection Cases\n",
    "print(\"True Detection Cases\")\n",
    "print(\"----------------------\")\n",
    "print(true.Amount.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "268aaa81-9b92-4eca-ba8f-79725cea42c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 30)\n",
      "(284807,)\n"
     ]
    }
   ],
   "source": [
    "# separating features(X) and Label(y)\n",
    "# Select all columns except the last for all rows\n",
    "X = datainput.iloc[:, :-1].values\n",
    "# Select the last column of all rows\n",
    "Y = datainput.iloc[:, -1].values\n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9d9fc7-9dfa-4431-aaec-c93bd72fa1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# train_test_split method\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccdc4ec1-554d-405c-9f7c-9317f3e64574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted values : [0 0 0 ... 0 0 0]\n",
      "The accuracy score using the DecisionTreeClassifier :  99.92802219023208\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(max_depth=4)\n",
    "classifier.fit(X_train, Y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(\"predicted values :\", predicted)\n",
    "# Accuracy\n",
    "DT = metrics.accuracy_score(Y_test, predicted) * 100\n",
    "print(\"The accuracy score using the DecisionTreeClassifier : \", DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cdbfd37-1262-4efa-a166-c8c9f195ee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision\n",
      "0.7444444444444445\n",
      "recall\n",
      "0.788235294117647\n",
      "f-Score\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "# Precision\n",
    "print(\"precision\")\n",
    "# Precision = TP / (TP + FP) (Where TP = True Positive, TN = True Negative, FP =\n",
    "precision = precision_score(Y_test, predicted, pos_label=1)\n",
    "print(precision_score(Y_test, predicted, pos_label=1))\n",
    "# Recall\n",
    "print(\"recall\")\n",
    "# Recall = TP / (TP + FN)\n",
    "recall = recall_score(Y_test, predicted, pos_label=1)\n",
    "print(recall_score(Y_test, predicted, pos_label=1))\n",
    "# f1-score\n",
    "print(\"f-Score\")\n",
    "# F - scores are a statistical method for determining accuracy accounting for‚ê£\n",
    "fscore = f1_score(Y_test, predicted, pos_label=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee2e9ba-43e4-4cba-bdfe-71b4089d613a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
